{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0069da5f",
   "metadata": {},
   "source": [
    "# Student Assignment: End-to-End ML Project (Completed)\n",
    "\n",
    "This notebook follows the requested structure: EDA, preprocessing, feature engineering, model building (Logistic Regression, Decision Tree, SVM, Random Forest, XGBoost), hyperparameter tuning, evaluation, and conclusions. The dataset used is `synthetic_dataset_10000x20.csv` (uploaded by you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136a1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load dataset (make sure file is in same working directory)\n",
    "data = pd.read_csv('synthetic_dataset_10000x20.csv')\n",
    "print('Dataset shape:', data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic EDA\n",
    "display(data.info())\n",
    "display(data.describe(include='all').T)\n",
    "print('\\nMissing values per column:\\n', data.isnull().sum())\n",
    "\n",
    "# Show unique values for categorical-ish columns (first 10 columns sample)\n",
    "for col in data.select_dtypes(include=['object','category']).columns:\n",
    "    print('\\n', col, '->', data[col].nunique(), 'unique values; sample:', data[col].dropna().unique()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0db6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target distribution\n",
    "if 'target_default_risk' in data.columns:\n",
    "    print('Target value counts:')\n",
    "    print(data['target_default_risk'].value_counts(normalize=False))\n",
    "    print('\\nTarget distribution (percent):')\n",
    "    print(data['target_default_risk'].value_counts(normalize=True)*100)\n",
    "else:\n",
    "    raise ValueError('Expected target column: target_default_risk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Numeric distributions: histograms and boxplots for numeric features\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c != 'target_default_risk']\n",
    "print('Numeric columns:', numeric_cols)\n",
    "\n",
    "# Plot histogram for first 8 numeric columns to keep notebook readable\n",
    "for col in numeric_cols[:8]:\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "    sns.histplot(data[col].dropna(), kde=True, ax=ax[0])\n",
    "    ax[0].set_title(f'Histogram of {col}')\n",
    "    sns.boxplot(x=data[col], ax=ax[1])\n",
    "    ax[1].set_title(f'Boxplot of {col}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2f919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correlation heatmap (numeric features)\n",
    "plt.figure(figsize=(10,8))\n",
    "corr = data[numeric_cols + ['target_default_risk']].corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='vlag', center=0)\n",
    "plt.title('Correlation heatmap (numeric features + target)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing & feature engineering\n",
    "df = data.copy()\n",
    "\n",
    "# Example: Fix common typos in 'education' if present\n",
    "if 'education' in df.columns:\n",
    "    df['education'] = df['education'].str.strip().str.lower().replace({\n",
    "        'bachlors':'bachelors', 'bachlor':'bachelors', 'bs':'bachelors', 'graduation':'bachelors'\n",
    "    })\n",
    "\n",
    "# Convert signup_date to datetime and create recency feature if present\n",
    "if 'signup_date' in df.columns:\n",
    "    df['signup_date'] = pd.to_datetime(df['signup_date'], errors='coerce')\n",
    "    max_date = df['signup_date'].max()\n",
    "    df['signup_recency_days'] = (max_date - df['signup_date']).dt.days.fillna(df['signup_date'].median())\n",
    "\n",
    "# Basic missing value imputation strategies\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "num_cols = [c for c in num_cols if c != 'target_default_risk']\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "\n",
    "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
    "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
    "\n",
    "print('After imputation missing values:', df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87915bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encoding and scaling pipeline\n",
    "ohe_cols = [c for c in cat_cols if df[c].nunique() <= 10 and c!='target_default_risk']\n",
    "ord_cols = [c for c in cat_cols if c not in ohe_cols and c!='target_default_risk']\n",
    "\n",
    "print('One-hot cols:', ohe_cols)\n",
    "print('Ordinal cols (fallback):', ord_cols)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False), ohe_cols),\n",
    "    ('ord', OrdinalEncoder(), ord_cols)\n",
    "], remainder='drop', sparse_threshold=0)\n",
    "\n",
    "# Prepare X and y\n",
    "X = df.drop(columns=['target_default_risk'])\n",
    "y = df['target_default_risk'].astype(int)\n",
    "\n",
    "# Fit preprocessor and transform\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "feature_names = []\n",
    "\n",
    "feature_names.extend(num_cols)\n",
    "if ohe_cols:\n",
    "    ohe_names = preprocessor.named_transformers_['ohe'].get_feature_names_out(ohe_cols).tolist()\n",
    "    feature_names.extend(ohe_names)\n",
    "feature_names.extend(ord_cols)\n",
    "\n",
    "print('Processed feature matrix shape:', X_processed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f16fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print('Train shape, Test shape:', X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb00d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, name='Model'):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    prec = precision_score(y_test, preds)\n",
    "    rec = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    print(f'--- {name} ---')\n",
    "    print('Accuracy:', round(acc,4))\n",
    "    print('Precision:', round(prec,4))\n",
    "    print('Recall:', round(rec,4))\n",
    "    print('F1-score:', round(f1,4))\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_test, preds))\n",
    "    print('\\nClassification Report:\\n', classification_report(y_test, preds))\n",
    "    return {'model': model, 'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1}\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_estimators=500)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, m in models.items():\n",
    "    results[name] = evaluate_model(m, X_train, y_train, X_test, y_test, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameter tuning: RandomizedSearchCV for RandomForest and XGBoost\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rf_param = {\n",
    "    'n_estimators': [200, 500, 800],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'min_samples_leaf': [1,2,4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf_search = RandomizedSearchCV(rf, rf_param, n_iter=20, scoring='f1', cv=cv, n_jobs=-1, verbose=1, random_state=42)\n",
    "rf_search.fit(X_train, y_train)\n",
    "print('RF best params:', rf_search.best_params_)\n",
    "print('RF best CV score (f1):', rf_search.best_score_)\n",
    "\n",
    "xgb_param = {\n",
    "    'n_estimators': [500, 1000, 1500],\n",
    "    'max_depth': [3,5,7,9],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'subsample': [0.6,0.8,1.0],\n",
    "    'colsample_bytree': [0.6,0.8,1.0],\n",
    "    'gamma': [0,1,5],\n",
    "    'min_child_weight': [1,3,5]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_search = RandomizedSearchCV(xgb, xgb_param, n_iter=30, scoring='f1', cv=cv, n_jobs=-1, verbose=1, random_state=42)\n",
    "xgb_search.fit(X_train, y_train)\n",
    "print('XGB best params:', xgb_search.best_params_)\n",
    "print('XGB best CV score (f1):', xgb_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate tuned models on test set\n",
    "best_rf = rf_search.best_estimator_\n",
    "best_xgb = xgb_search.best_estimator_\n",
    "\n",
    "print('\\nEvaluating tuned Random Forest on test set:')\n",
    "rf_results = evaluate_model(best_rf, X_train, y_train, X_test, y_test, name='RandomForest_Tuned')\n",
    "\n",
    "print('\\nEvaluating tuned XGBoost on test set:')\n",
    "xgb_results = evaluate_model(best_xgb, X_train, y_train, X_test, y_test, name='XGBoost_Tuned')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92642bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature importance (from XGBoost tuned)\n",
    "try:\n",
    "    xgb.plot_importance(best_xgb, importance_type='gain')\n",
    "    plt.title('XGBoost Feature Importance (gain)')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('Could not plot importance:', e)\n",
    "\n",
    "# Summary table\n",
    "summary = []\n",
    "for name, r in results.items():\n",
    "    summary.append({\n",
    "        'model': name,\n",
    "        'accuracy': r['accuracy'],\n",
    "        'precision': r['precision'],\n",
    "        'recall': r['recall'],\n",
    "        'f1': r['f1']\n",
    "    })\n",
    "\n",
    "summary.append({'model':'RandomForest_Tuned', 'accuracy': rf_results['accuracy'], 'precision': rf_results['precision'], 'recall': rf_results['recall'], 'f1': rf_results['f1']})\n",
    "summary.append({'model':'XGBoost_Tuned', 'accuracy': xgb_results['accuracy'], 'precision': xgb_results['precision'], 'recall': xgb_results['recall'], 'f1': xgb_results['f1']})\n",
    "\n",
    "summary_df = pd.DataFrame(summary).set_index('model')\n",
    "display(summary_df)\n",
    "\n",
    "print('\\nConclusions:')\n",
    "print(' - Review preprocessing choices (imputation, encoding).')\n",
    "print(' - Tuned models likely perform better; consider ensembling/stacking if you want further gains.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74041eb8",
   "metadata": {},
   "source": [
    "## Files created\n",
    "\n",
    "- `student_assignment_completed.ipynb` — Completed notebook with EDA, preprocessing, models, tuning, and conclusions.\n",
    "- `assignment_report.md` — Short 1-2 page report summarizing key findings and conclusions.\n",
    "\n",
    "You can download both files using the links provided after running the notebook."
   ]
  }
 ],
 "metadata": {
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
